{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laporan Tugas 3 Machine Learning : Q-Learning\n",
    "\n",
    "## Nama   : Septian Dwi Indradi\n",
    "## Kelas  : IF-39-10\n",
    "## NIM  : 1301154164"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Analisis Masalah\n",
    "\n",
    "Diketahui sebuah grid world berukuran 10x10, dimana angka-angka dalam kotak menyatakan reward. Sebuah agent berada di posisi start (1,1) dan goal berada di posisi(10,10). Agent dapat melakukan empat aksi, yaitu N (North), S (South), W (West), dan E (East) yang menyatakan arah ke atas, bawah, kiri dan kanan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-5</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-4</td>\n",
       "      <td>-2</td>\n",
       "      <td>-5</td>\n",
       "      <td>-3</td>\n",
       "      <td>-5</td>\n",
       "      <td>-5</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "      <td>-5</td>\n",
       "      <td>-5</td>\n",
       "      <td>-4</td>\n",
       "      <td>-3</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3</td>\n",
       "      <td>-5</td>\n",
       "      <td>-2</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1</td>\n",
       "      <td>-4</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-4</td>\n",
       "      <td>-3</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-4</td>\n",
       "      <td>-2</td>\n",
       "      <td>-5</td>\n",
       "      <td>-2</td>\n",
       "      <td>-4</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-4</td>\n",
       "      <td>-3</td>\n",
       "      <td>-2</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "      <td>-4</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-4</td>\n",
       "      <td>-2</td>\n",
       "      <td>-5</td>\n",
       "      <td>-4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-4</td>\n",
       "      <td>-5</td>\n",
       "      <td>-5</td>\n",
       "      <td>-2</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1</td>\n",
       "      <td>-4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-5</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-4</td>\n",
       "      <td>-3</td>\n",
       "      <td>-5</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8    9\n",
       "0 -1 -3 -5 -1 -3 -3 -5 -5 -1  100\n",
       "1 -2 -1 -1 -4 -2 -5 -3 -5 -5   -5\n",
       "2 -3 -4 -4 -1 -3 -5 -5 -4 -3   -5\n",
       "3 -3 -5 -2 -5 -1 -4 -5 -1 -3   -4\n",
       "4 -4 -3 -3 -2 -1 -1 -1 -4 -3   -4\n",
       "5 -4 -2 -5 -2 -4 -5 -1 -2 -2   -4\n",
       "6 -4 -3 -2 -3 -1 -3 -4 -3 -1   -3\n",
       "7 -4 -2 -5 -4 -1 -4 -5 -5 -2   -4\n",
       "8 -2 -1 -1 -4 -1 -3 -5 -1 -4   -1\n",
       "9 -5 -3 -1 -2 -4 -3 -5 -2 -2   -2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "reward_table = []\n",
    "for data in open('DataTugasML3.txt'):\n",
    "    reward_table.append(data.split())\n",
    "\n",
    "reward_table = pd.DataFrame(pd.DataFrame(reward_table).astype(int))\n",
    "reward_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Akan dibangun sebuah sistem Q-Learning untuk menemukan optimum policy sehingga agent yang berada di posisi Start (1,1) mampu menemukan goal yang berada di posisi (10,10) dengan mendapatkan total reward maksimum pada grid world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Desain\n",
    "Beberapa parameter yang digunakan pada sistem Q-Learning yang dibangun diantaranya :\n",
    "1. ⍺ (Alpha) : Merupakan learning rate yang berpengaruh terhadap seberapa cepat sistem akan konvergen.\n",
    "2. ɣ (Gamma) : Merupakan discount factor yang akan berpengaruh terhadap nilai reward pada step-step yang akan dilalui dan menentukan seberapa besar pengaruh reward di step-step yang akan datang. Semakin besar gamma maka future reward akan semakin diperhitungkan.\n",
    "3. ϵ (Epsilon) : Disebut juga greedy policy merupakan parameter yang menentukan seberapa besar peluang agent akan melakukan eksplorasi dibanding eksploitasi. Semakin besar epsilon maka peluang eksploitasi semakin besar, semakin kecil epsilon maka peluang eksplorasi semakin besar. Epsilon juga digunakan untuk menghindari overfit.\n",
    "\n",
    "Sistem Q-Learning yang dibangun memiliki parameter sebagai berikut : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIONS = ['up','down','left','right']\n",
    "N_STATES = 100\n",
    "ALPHA = 0.5\n",
    "GAMMA = 0.9\n",
    "EPSILON = 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimum policy akan didapatkan dari Q-Table yang akan terupdate selama dilakukan iterasi sebanyak n episode. Q-Table berukuran 100x4 dimana 100 merupakan jumlah state dan 4 merupakan jumlah action yang dapat dilakukan. Q-Table diinisialisasi menggunakan fungsi build_q_table(n_states,actions) berikut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_q_table(n_states, actions) :\n",
    "    table = pd.DataFrame(\n",
    "        (np.zeros((n_states,len(actions)))),\n",
    "        columns=actions, \n",
    "    )\n",
    "    index = []\n",
    "    for i in range(10) :\n",
    "        for j in range(10) :\n",
    "            index.append(str(i)+','+str(j))\n",
    "            \n",
    "    table['state'] = pd.DataFrame(index)\n",
    "    table.set_index('state',inplace=True)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setiap episode, action diambil secara random atau mencari nilai Q maksimum dari next_state, jika menggunakan epsilon maka di random suatu angka dan akan dibandingkan dengan nilai epsilon, jika hasil random lebih besar maka action diambil secara random. Action dipilih menggunakan fungsi choose_action(state,q_table,testMode=False,EPSILON=0) berikut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_action(state, q_table,testMode=False,EPSILON=0) :\n",
    "    state_actions = q_table.loc[state]\n",
    "    if testMode :\n",
    "        action = state_actions.idxmax()\n",
    "    else:\n",
    "        if (state_actions.all == 0) or (np.random.uniform() > EPSILON) :\n",
    "            action = np.random.choice(ACTIONS)\n",
    "        else:\n",
    "            action = state_actions.idxmax()\n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dibuat fungsi get_env_feedback untuk mendapatkan reward dan next_state berdasarkan current state dan action yang dipilih."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_env_feedback(state, action, reward_table) :\n",
    "    state = state.split(',')\n",
    "    state = [int(state[0]),int(state[1])]\n",
    "    if action == 'up' :\n",
    "        if state == [1,9] :\n",
    "            return 'terminal',100\n",
    "        elif state[0] == 0 :\n",
    "            next_state = state\n",
    "            reward = -100\n",
    "        else:\n",
    "            next_state = [state[0]-1,state[1]]\n",
    "            reward = reward_table.at[next_state[0],next_state[1]]\n",
    "    elif action == 'down' :\n",
    "        if state[0] == 9 :\n",
    "            next_state = state\n",
    "            reward = -100\n",
    "        else:\n",
    "            next_state = [state[0]+1,state[1]]\n",
    "            reward = reward_table.at[next_state[0],next_state[1]]\n",
    "    elif action == 'left' :\n",
    "        if state[1] == 0 :\n",
    "            next_state = state\n",
    "            reward = -100\n",
    "        else:\n",
    "            next_state = [state[0],state[1]-1]\n",
    "            reward = reward_table.at[next_state[0],next_state[1]]\n",
    "    else: \n",
    "        if state == [0,8] :\n",
    "            return 'terminal',100\n",
    "        elif state[1] == 9 :\n",
    "            next_state = state\n",
    "            reward = -100\n",
    "        else:\n",
    "            next_state = [state[0],state[1]+1]\n",
    "            reward = reward_table.at[next_state[0],next_state[1]]\n",
    "    \n",
    "    next_state = str(next_state[0]) + ',' + str(next_state[1])\n",
    "    return next_state,reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fungsi getPath untuk mendapatkan optimum policy dari Q-Table yang sudah dibangun. Fungsi akan mengoutputkan action-action yang dilakukan dan total reward yang didapatkan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPath(q_table) :\n",
    "    step_counter = 0\n",
    "    state = '9,0'\n",
    "    is_terminated = False\n",
    "    \n",
    "    finalReward = 0.0\n",
    "    steps = []\n",
    "    \n",
    "    while not is_terminated:\n",
    "        action = choose_action(state, q_table,testMode=True)\n",
    "        next_state, reward = get_env_feedback(state, action,reward_table)\n",
    "        finalReward += reward\n",
    "        steps.append(action) \n",
    "        if next_state == 'terminal' :\n",
    "            is_terminated = True\n",
    "        state = next_state\n",
    "        step_counter += 1\n",
    "        \n",
    "    print(steps)\n",
    "    print('Total reward =',finalReward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fungsi q_learning merupakan algoritma utama dari sistem Q-Learning yang dibangun. Pada proses learning, setiap iterasi / episode agent akan berjalan sesuai action yang dipilih, Q-Table kemudian akan di update dan agent akan berhenti ketika telah mencapai goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_learning(q_table,MAX_EPISODES=100,EPSILON=0) :\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    for episode in range(MAX_EPISODES):\n",
    "        step_counter = 0\n",
    "        state = '9,0'\n",
    "        is_terminated = False\n",
    "    \n",
    "        finalReward = 0.0    \n",
    "        \n",
    "        while not is_terminated:\n",
    "            action = choose_action(state, q_table, testMode=False, EPSILON=EPSILON)\n",
    "            next_state, reward = get_env_feedback(state, action,reward_table)\n",
    "            finalReward += reward\n",
    "            q_predict = q_table.loc[state,action]\n",
    "            if next_state != 'terminal' :\n",
    "                q_target = reward + GAMMA * q_table.loc[next_state].max()    \n",
    "            if next_state == 'terminal' :\n",
    "                is_terminated = True\n",
    "                q_target = reward\n",
    "            q_table.loc[state,action] += ALPHA * (q_target - q_predict)\n",
    "            state = next_state\n",
    "            step_counter += 1\n",
    "        \n",
    "        if episode % 10 == 0 :\n",
    "            print('\\rBuilding Q-Table : %i of %i episode'%(episode,MAX_EPISODES),end='')\n",
    "    print('\\rBuilding Q-Table : %i of %i episode'%(episode+1,MAX_EPISODES))\n",
    "    print('Finished in %.4f seconds'%(time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Hasil Eksperimen\n",
    "Eksperimen dilakukan dengan menginisialisasi Q-Table, kemudian melakukan learning sebanyak 100 episode dengan parameter-parameter yang telah ditentukan sebelumnya. Setelah dilakukan q-learning, didapatkan optimum policy yaitu :\n",
    "#### ['up', 'right', 'right', 'right', 'right', 'up', 'up', 'up', 'up', 'right', 'right', 'right', 'up', 'right', 'up', 'up', 'up', 'right']\n",
    "#### Total reward = 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Q-Table : 100 of 100 episode\n",
      "Finished in 4.3046 seconds\n",
      "['up', 'right', 'right', 'right', 'right', 'up', 'up', 'up', 'up', 'right', 'right', 'right', 'up', 'right', 'up', 'up', 'up', 'right']\n",
      "Total reward = 65.0\n"
     ]
    }
   ],
   "source": [
    "q_table = build_q_table(N_STATES,ACTIONS)\n",
    "q_learning(q_table,MAX_EPISODES=100,EPSILON=EPSILON)\n",
    "getPath(q_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q-Table kemudian disimpan dalam file q-table.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('q-table.xlsx')\n",
    "q_table.to_excel(writer,'sheet1',index=False)\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
